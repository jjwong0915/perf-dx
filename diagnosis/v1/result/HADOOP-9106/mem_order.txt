[0. 0.] /************************************************************
[0. 0.] STARTUP_MSG: Starting SecondaryNameNode
[0. 0.] STARTUP_MSG:   user = jjwong0915
[0. 0.] STARTUP_MSG:   args = []
[0. 0.] ************************************************************/
[0. 0.] /************************************************************
[0. 0.] ************************************************************/
[0. 0.] /************************************************************
[0. 0.] STARTUP_MSG: Starting SecondaryNameNode
[0. 0.] STARTUP_MSG:   user = jjwong0915
[0. 0.] STARTUP_MSG:   args = []
[0. 0.] ************************************************************/
[0. 0.] /************************************************************
[0. 0.] STARTUP_MSG: Starting NameNode
[0. 0.] STARTUP_MSG:   user = jjwong0915
[0. 0.] STARTUP_MSG:   args = []
[0. 0.] ************************************************************/
[0. 0.] INFO BlockStateChange: BLOCK* processReport 0x87ba53e2ea37ccf: Processing first storage report for DS-39f00f43-9d22-446b-8189-e4fc6a57c36f from datanode f58eda39-4a23-440d-8313-5961ae2f38ee
[0. 0.] /************************************************************
[0. 0.] ************************************************************/
[0. 0.] /************************************************************
[0. 0.] STARTUP_MSG: Starting NameNode
[0. 0.] STARTUP_MSG:   user = jjwong0915
[0. 0.] STARTUP_MSG:   args = []
[0. 0.] ************************************************************/
[0. 0.] name space=6
[0. 0.] storage space=1102236587
[0. 0.] INFO BlockStateChange: BLOCK* processReport 0xdf2bff20965f3b1d: Processing first storage report for DS-39f00f43-9d22-446b-8189-e4fc6a57c36f from datanode f58eda39-4a23-440d-8313-5961ae2f38ee
[0. 0.] INFO impl.MetricsSystemImpl: JobTracker metrics system started
[0. 0.] /************************************************************
[0. 0.] STARTUP_MSG: Starting DataNode
[0. 0.] STARTUP_MSG:   user = jjwong0915
[0. 0.] STARTUP_MSG:   args = []
[0. 0.] ************************************************************/
[0. 0.] Caused by: java.io.EOFException
[0. 0.] /************************************************************
[0. 0.] ************************************************************/
[0. 0.] /************************************************************
[0. 0.] STARTUP_MSG: Starting DataNode
[0. 0.] STARTUP_MSG:   user = jjwong0915
[0. 0.] STARTUP_MSG:   args = []
[0. 0.] ************************************************************/
[2.280000e+02 6.991872e+07] name space=1
[2.502000e+02 7.819264e+07] INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
[2.502000e+02 7.819264e+07] INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
[2.502000e+02 7.819264e+07] INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
[2.502000e+02 7.819264e+07] INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
[2.502000e+02 7.819264e+07] INFO impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
[2.502000e+02 7.819264e+07] 	at org.apache.hadoop.ipc.Client.call(Client.java:1441)
[2.502000e+02 7.819264e+07] 	at com.sun.proxy.$Proxy10.getFileInfo(Unknown Source)
[2.502000e+02 7.819264e+07] 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[2.502000e+02 7.819264e+07] 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
[2.502000e+02 7.819264e+07] 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[2.502000e+02 7.819264e+07] 	at java.lang.reflect.Method.invoke(Method.java:498)
[2.502000e+02 7.819264e+07] 	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:398)
[2.502000e+02 7.819264e+07] 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:163)
[2.502000e+02 7.819264e+07] 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:155)
[2.502000e+02 7.819264e+07] INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
[2.502000e+02 7.819264e+07] WARN io.netty.channel.DefaultChannelId: Failed to find a usable hardware address from the network interfaces; using random bytes: 27:94:ff:c2:48:50:56:e1
[2.502000e+02 7.819264e+07] 	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
[2.502000e+02 7.819264e+07] 	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
[2.502000e+02 7.819264e+07] 	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
[2.502000e+02 7.819264e+07] 	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
[2.502000e+02 7.819264e+07] 	at org.apache.hadoop.ipc.Client.call(Client.java:1441)
[2.502000e+02 7.819264e+07] 	at com.sun.proxy.$Proxy15.sendHeartbeat(Unknown Source)
[2.502000e+02 7.819264e+07] 	at java.lang.Thread.run(Thread.java:750)
[2.502000e+02 7.819264e+07] 	at java.io.DataInputStream.readInt(DataInputStream.java:392)
[2.502000e+02 7.819264e+07] INFO org.mortbay.log: Logging to org.slf4j.impl.Log4jLoggerAdapter(org.mortbay.log) via org.mortbay.log.Slf4jLog
[2.502000e+02 7.819264e+07] WARN io.netty.channel.DefaultChannelId: Failed to find a usable hardware address from the network interfaces; using random bytes: 5f:54:c0:77:ed:cb:46:44
[4.7820000e+02 1.4811136e+08] INFO org.mortbay.log: jetty-6.1.26
[4.7820000e+02 1.4811136e+08] INFO org.mortbay.log: jetty-6.1.26
[4.7820000e+02 1.4811136e+08] INFO org.mortbay.log: jetty-6.1.26
[4.7820000e+02 1.4811136e+08] INFO org.mortbay.log: jetty-6.1.26
[4.7820000e+02 1.4811136e+08] INFO org.mortbay.log: jetty-6.1.26
[4.7820000e+02 1.4811136e+08] INFO org.mortbay.log: jetty-6.1.26
[4.8930000e+02 1.5224832e+08] INFO org.mortbay.log: Started SelectChannelConnector@localhost:35731
[4.8930000e+02 1.5224832e+08] INFO org.mortbay.log: Started SelectChannelConnector@localhost:46461
[5.0040000e+02 1.5638528e+08] 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1499)
[5.0040000e+02 1.5638528e+08] 	at org.apache.hadoop.ipc.Client.call(Client.java:1351)
[5.0040000e+02 1.5638528e+08] 	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1499)
[5.0040000e+02 1.5638528e+08] 	at org.apache.hadoop.ipc.Client.call(Client.java:1351)
[5.0040000e+02 1.5638528e+08] 	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1153)
[5.0040000e+02 1.5638528e+08] 	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1048)
[5.8750000e+02 1.8382848e+08] STARTUP_MSG:   java = 1.8.0_362
[5.8750000e+02 1.8382848e+08] STARTUP_MSG:   java = 1.8.0_362
[5.8750000e+02 1.8382848e+08] STARTUP_MSG:   java = 1.8.0_362
[5.8750000e+02 1.8382848e+08] storage space=0
[5.8750000e+02 1.8382848e+08] storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
[5.8750000e+02 1.8382848e+08] INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741835_1011, replicas=127.0.0.1:9866 for /user/jjwong0915/input/_temporary/0/_temporary/attempt_local227564641_0001_m_000000_0/part-m-00000
[5.8750000e+02 1.8382848e+08] INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741841_1017, replicas=127.0.0.1:9866 for /user/jjwong0915/input/_temporary/0/_temporary/attempt_local227564641_0001_m_000000_0/part-m-00000
[5.8750000e+02 1.8382848e+08] INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741842_1018, replicas=127.0.0.1:9866 for /user/jjwong0915/output/_temporary/0/_temporary/attempt_local1322365963_0001_r_000000_0/part-r-00000
[5.8750000e+02 1.8382848e+08] INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/jjwong0915/output/_temporary/0/_temporary/attempt_local1322365963_0001_r_000000_0/part-r-00000 is closed by DFSClient_NONMAPREDUCE_1135516224_1
[5.8750000e+02 1.8382848e+08] STARTUP_MSG:   java = 1.8.0_362
[5.8750000e+02 1.8382848e+08] The reported blocks 0 needs additional 8 blocks to reach the threshold 0.9990 of total blocks 9.
[5.8750000e+02 1.8382848e+08] The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
[5.8750000e+02 1.8382848e+08] storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0
[5.8750000e+02 1.8382848e+08] STARTUP_MSG:   java = 1.8.0_362
[5.8750000e+02 1.8382848e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1805970196;bpid=BP-29133155-10.142.0.8-1679943450225;lv=-57;nsInfo=lv=-64;cid=CID-95b932b1-e70d-4922-a632-09a5454bb088;nsid=1805970196;c=1679943450225;bpid=BP-29133155-10.142.0.8-1679943450225;dnuuid=null
[5.8750000e+02 1.8382848e+08] STARTUP_MSG:   java = 1.8.0_362
[5.8750000e+02 1.8382848e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Setting up storage: nsid=1805970196;bpid=BP-29133155-10.142.0.8-1679943450225;lv=-57;nsInfo=lv=-64;cid=CID-95b932b1-e70d-4922-a632-09a5454bb088;nsid=1805970196;c=1679943450225;bpid=BP-29133155-10.142.0.8-1679943450225;dnuuid=f58eda39-4a23-440d-8313-5961ae2f38ee
[6.6350000e+02 2.0713472e+08] STARTUP_MSG:   version = 3.0.0-alpha1
[6.6350000e+02 2.0713472e+08] STARTUP_MSG:   version = 3.0.0-alpha1
[6.6350000e+02 2.0713472e+08] STARTUP_MSG:   version = 3.0.0-alpha1
[6.6350000e+02 2.0713472e+08] STARTUP_MSG:   version = 3.0.0-alpha1
[6.6350000e+02 2.0713472e+08] The reported blocks 8 has reached the threshold 0.9990 of total blocks 9. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 29 seconds.
[6.6350000e+02 2.0713472e+08] The reported blocks 9 has reached the threshold 0.9990 of total blocks 9. The number of live datanodes 1 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 9 seconds.
[6.6350000e+02 2.0713472e+08] STARTUP_MSG:   version = 3.0.0-alpha1
[6.6350000e+02 2.0713472e+08] STARTUP_MSG:   version = 3.0.0-alpha1
[8.155000e+02 2.537472e+08] INFO BlockStateChange: BLOCK* processReport 0x87ba53e2ea37ccf: from storage DS-39f00f43-9d22-446b-8189-e4fc6a57c36f node DatanodeRegistration(127.0.0.1:9866, datanodeUuid=f58eda39-4a23-440d-8313-5961ae2f38ee, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-95b932b1-e70d-4922-a632-09a5454bb088;nsid=1805970196;c=1679943450225), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
[8.155000e+02 2.537472e+08] INFO BlockStateChange: BLOCK* processReport 0xdf2bff20965f3b1d: from storage DS-39f00f43-9d22-446b-8189-e4fc6a57c36f node DatanodeRegistration(127.0.0.1:9866, datanodeUuid=f58eda39-4a23-440d-8313-5961ae2f38ee, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-95b932b1-e70d-4922-a632-09a5454bb088;nsid=1805970196;c=1679943450225), blocks: 9, hasStaleStorage: false, processing time: 28 msecs, invalidatedBlocks: 0
[8.155000e+02 2.537472e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38390, dest: /127.0.0.1:9866, bytes: 884, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_66444181_1, offset: 0, srvID: f58eda39-4a23-440d-8313-5961ae2f38ee, blockid: BP-29133155-10.142.0.8-1679943450225:blk_1073741826_1002, duration: 3817570
[8.155000e+02 2.537472e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38398, dest: /127.0.0.1:9866, bytes: 867, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_66444181_1, offset: 0, srvID: f58eda39-4a23-440d-8313-5961ae2f38ee, blockid: BP-29133155-10.142.0.8-1679943450225:blk_1073741828_1004, duration: 2396280
[8.155000e+02 2.537472e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:49746, dest: /127.0.0.1:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1627593271_1, offset: 0, srvID: f58eda39-4a23-440d-8313-5961ae2f38ee, blockid: BP-29133155-10.142.0.8-1679943450225:blk_1073741833_1009, duration: 2395458988
[8.155000e+02 2.537472e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50562, dest: /127.0.0.1:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1627593271_1, offset: 0, srvID: f58eda39-4a23-440d-8313-5961ae2f38ee, blockid: BP-29133155-10.142.0.8-1679943450225:blk_1073741834_1010, duration: 1519419023
[8.155000e+02 2.537472e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50588, dest: /127.0.0.1:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1627593271_1, offset: 0, srvID: f58eda39-4a23-440d-8313-5961ae2f38ee, blockid: BP-29133155-10.142.0.8-1679943450225:blk_1073741836_1012, duration: 1535220092
[8.155000e+02 2.537472e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:45740, dest: /127.0.0.1:9866, bytes: 36982354, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1135516224_1, offset: 0, srvID: f58eda39-4a23-440d-8313-5961ae2f38ee, blockid: BP-29133155-10.142.0.8-1679943450225:blk_1073741842_1018, duration: 3549134022
[8.2660000e+02 2.5788416e+08] java.io.EOFException: End of File Exception between local host is: "hadoop-1.us-east1-b.c.workstation-360918.internal/10.142.0.8"; destination host is: "localhost":9000; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
[8.3770000e+02 2.6202112e+08] INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:9868
[8.3770000e+02 2.6202112e+08] INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:9868
[8.3770000e+02 2.6202112e+08] INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:9870
[8.3770000e+02 2.6202112e+08] INFO org.mortbay.log: Started SelectChannelConnector@0.0.0.0:9870
[1.0657000e+03 3.3193984e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38396, dest: /127.0.0.1:9866, bytes: 9683, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_66444181_1, offset: 0, srvID: f58eda39-4a23-440d-8313-5961ae2f38ee, blockid: BP-29133155-10.142.0.8-1679943450225:blk_1073741827_1003, duration: 3015870
[1.0657000e+03 3.3193984e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38404, dest: /127.0.0.1:9866, bytes: 620, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_66444181_1, offset: 0, srvID: f58eda39-4a23-440d-8313-5961ae2f38ee, blockid: BP-29133155-10.142.0.8-1679943450225:blk_1073741829_1005, duration: 2476470
[1.0657000e+03 3.3193984e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38420, dest: /127.0.0.1:9866, bytes: 3518, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_66444181_1, offset: 0, srvID: f58eda39-4a23-440d-8313-5961ae2f38ee, blockid: BP-29133155-10.142.0.8-1679943450225:blk_1073741830_1006, duration: 9883929
[1.0657000e+03 3.3193984e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38434, dest: /127.0.0.1:9866, bytes: 5933, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_66444181_1, offset: 0, srvID: f58eda39-4a23-440d-8313-5961ae2f38ee, blockid: BP-29133155-10.142.0.8-1679943450225:blk_1073741831_1007, duration: 2590310
[1.0657000e+03 3.3193984e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38440, dest: /127.0.0.1:9866, bytes: 690, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_66444181_1, offset: 0, srvID: f58eda39-4a23-440d-8313-5961ae2f38ee, blockid: BP-29133155-10.142.0.8-1679943450225:blk_1073741832_1008, duration: 3208550
[1.0657000e+03 3.3193984e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50574, dest: /127.0.0.1:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1627593271_1, offset: 0, srvID: f58eda39-4a23-440d-8313-5961ae2f38ee, blockid: BP-29133155-10.142.0.8-1679943450225:blk_1073741835_1011, duration: 1572413617
[1.0657000e+03 3.3193984e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50604, dest: /127.0.0.1:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1627593271_1, offset: 0, srvID: f58eda39-4a23-440d-8313-5961ae2f38ee, blockid: BP-29133155-10.142.0.8-1679943450225:blk_1073741837_1013, duration: 1285012566
[1.0657000e+03 3.3193984e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50610, dest: /127.0.0.1:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1627593271_1, offset: 0, srvID: f58eda39-4a23-440d-8313-5961ae2f38ee, blockid: BP-29133155-10.142.0.8-1679943450225:blk_1073741838_1014, duration: 1311507743
[1.0657000e+03 3.3193984e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50612, dest: /127.0.0.1:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1627593271_1, offset: 0, srvID: f58eda39-4a23-440d-8313-5961ae2f38ee, blockid: BP-29133155-10.142.0.8-1679943450225:blk_1073741839_1015, duration: 1238237720
[1.0657000e+03 3.3193984e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:45722, dest: /127.0.0.1:9866, bytes: 28494763, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1627593271_1, offset: 0, srvID: f58eda39-4a23-440d-8313-5961ae2f38ee, blockid: BP-29133155-10.142.0.8-1679943450225:blk_1073741841_1017, duration: 280025722
[1.2732000e+03 3.9923712e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 54 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 15 Number of syncs: 39 SyncTimes(ms): 46 
[1.2732000e+03 3.9923712e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 54 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 15 Number of syncs: 40 SyncTimes(ms): 47 
[1.2732000e+03 3.9923712e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 42 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 22 Number of syncs: 18 SyncTimes(ms): 338 
[1.2732000e+03 3.9923712e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 45 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 24 Number of syncs: 19 SyncTimes(ms): 339 
[1.3714000e+03 4.3081728e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 108 Number of syncs: 2 SyncTimes(ms): 7 
[1.3714000e+03 4.3081728e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 2 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 108 Number of syncs: 3 SyncTimes(ms): 8 
[1.5012000e+03 4.6915584e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0xdf2bff20965f3b1d,  containing 1 storage report(s), of which we sent 1. The reports had 9 total blocks and used 1 RPC(s). This took 4 msec to generate and 157 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
[1.5234000e+03 4.7742976e+08] STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r a990d2ebcd6de5d7dc2d3684930759b0f0ea4dc3; compiled by 'andrew' on 2016-08-30T07:02Z
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
[1.5234000e+03 4.7742976e+08] STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r a990d2ebcd6de5d7dc2d3684930759b0f0ea4dc3; compiled by 'andrew' on 2016-08-30T07:02Z
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.secondary is not defined
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context secondary
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
[1.5234000e+03 4.7742976e+08] STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r a990d2ebcd6de5d7dc2d3684930759b0f0ea4dc3; compiled by 'andrew' on 2016-08-30T07:02Z
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 11 msec
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
[1.5234000e+03 4.7742976e+08] STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r a990d2ebcd6de5d7dc2d3684930759b0f0ea4dc3; compiled by 'andrew' on 2016-08-30T07:02Z
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.namenode is not defined
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.util.GSet: Computing capacity for map BlocksMap
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.util.GSet: Computing capacity for map INodeMap
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.util.GSet: Computing capacity for map cachedBlocks
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.util.GSet: Computing capacity for map NameNodeRetryCache
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9000: starting
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.hdfs.StateChange: STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 12 msec
[1.5234000e+03 4.7742976e+08] STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r a990d2ebcd6de5d7dc2d3684930759b0f0ea4dc3; compiled by 'andrew' on 2016-08-30T07:02Z
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
[1.5234000e+03 4.7742976e+08] STARTUP_MSG:   build = https://git-wip-us.apache.org/repos/asf/hadoop.git -r a990d2ebcd6de5d7dc2d3684930759b0f0ea4dc3; compiled by 'andrew' on 2016-08-30T07:02Z
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpRequestLog: Http request log for http.requests.datanode is not defined
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.http.HttpServer2: Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.util.JvmPauseMonitor: Starting JVM pause monitor
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.ipc.CallQueueManager: Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
[1.5234000e+03 4.7742976e+08] INFO org.apache.hadoop.ipc.Server: IPC Server listener on 9867: starting
[1.59940e+03 5.00736e+08] INFO impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
[1.6216000e+03 5.0900992e+08] INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
[1.6216000e+03 5.0900992e+08] INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
[1.6216000e+03 5.0900992e+08] INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
[1.6216000e+03 5.0900992e+08] INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
[1.6216000e+03 5.0900992e+08] INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
[1.6216000e+03 5.0900992e+08] INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
[1.6216000e+03 5.0900992e+08] INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
[1.6216000e+03 5.0900992e+08] INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
[1.6216000e+03 5.0900992e+08] INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
[1.6216000e+03 5.0900992e+08] INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
[1.6216000e+03 5.0900992e+08] INFO org.apache.hadoop.util.GSet: capacity      = 2^21 = 2097152 entries
[1.6216000e+03 5.0900992e+08] INFO org.apache.hadoop.util.GSet: capacity      = 2^20 = 1048576 entries
[1.6216000e+03 5.0900992e+08] INFO org.apache.hadoop.util.GSet: capacity      = 2^18 = 262144 entries
[1.6216000e+03 5.0900992e+08] INFO org.apache.hadoop.util.GSet: capacity      = 2^15 = 32768 entries
[1.7514000e+03 5.4734848e+08] INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
[1.7514000e+03 5.4734848e+08] INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
[1.7514000e+03 5.4734848e+08] INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
[1.7514000e+03 5.4734848e+08] INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
[1.7514000e+03 5.4734848e+08] INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/jjwong0915/input/capacity-scheduler.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_66444181_1
[1.7514000e+03 5.4734848e+08] INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/jjwong0915/input/kms-acls.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_66444181_1
[1.7514000e+03 5.4734848e+08] INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/jjwong0915/input/kms-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_66444181_1
[1.7514000e+03 5.4734848e+08] INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/jjwong0915/input/yarn-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_66444181_1
[1.7514000e+03 5.4734848e+08] INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/jjwong0915/output/_SUCCESS is closed by DFSClient_NONMAPREDUCE_1135516224_1
[1.7514000e+03 5.4734848e+08] INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
[1.7514000e+03 5.4734848e+08] INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9000
[1.7514000e+03 5.4734848e+08] INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 1 racks and 1 datanodes
[1.7514000e+03 5.4734848e+08] INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
[1.7514000e+03 5.4734848e+08] INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
[1.7514000e+03 5.4734848e+08] INFO org.apache.hadoop.ipc.Server: Starting Socket Reader #1 for port 9867
[1.7514000e+03 5.4734848e+08] INFO org.apache.hadoop.hdfs.server.common.Storage: Using 1 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=1, dataDirs=1)
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: registered UNIX signal handlers for [TERM, HUP, INT]
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: SecondaryNameNode metrics system started
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.hdfs.server.namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: NameNode metrics system started
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.http.HttpServer2: Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.http.HttpServer2: addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON. 
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode extension entered. 
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode ON, in safe mode extension. 
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.hdfs.StateChange: STATE* Safe mode is OFF
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 33 secs
[1.773600e+03 5.556224e+08] 	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: registered UNIX signal handlers for [TERM, HUP, INT]
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: DataNode metrics system started
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.http.HttpServer2: Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
[1.773600e+03 5.556224e+08] INFO org.apache.hadoop.ipc.Server: IPC Server Responder: starting
[1.8496000e+03 5.7892864e+08] INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
[1.8496000e+03 5.7892864e+08] INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9868
[1.8496000e+03 5.7892864e+08] INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
[1.8496000e+03 5.7892864e+08] INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9868
[1.8496000e+03 5.7892864e+08] INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
[1.8496000e+03 5.7892864e+08] INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
[1.8496000e+03 5.7892864e+08] INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
[1.8496000e+03 5.7892864e+08] INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 9870
[1.8496000e+03 5.7892864e+08] INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
[1.8496000e+03 5.7892864e+08] INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 35731
[1.8496000e+03 5.7892864e+08] INFO org.apache.hadoop.metrics2.impl.MetricsConfig: loaded properties from hadoop-metrics2.properties
[1.8496000e+03 5.7892864e+08] INFO org.apache.hadoop.http.HttpServer2: Jetty bound to port 46461
[1.860700e+03 5.830656e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Successfully sent block report 0x87ba53e2ea37ccf,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 74 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
[1.9700000e+03 6.1878272e+08] INFO org.apache.hadoop.hdfs.server.common.Storage: Storage directory /tmp/hadoop-jjwong0915/dfs/data is not formatted for namespace 1805970196. Formatting...
[2.0016000e+03 6.2554112e+08] INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
[2.0016000e+03 6.2554112e+08] INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
[2.0016000e+03 6.2554112e+08] INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
[2.0016000e+03 6.2554112e+08] INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
[2.0016000e+03 6.2554112e+08] INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
[2.0016000e+03 6.2554112e+08] INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
[2.0016000e+03 6.2554112e+08] INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
[2.0016000e+03 6.2554112e+08] INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
[2.0016000e+03 6.2554112e+08] INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
[2.0016000e+03 6.2554112e+08] INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
[2.0016000e+03 6.2554112e+08] INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/jjwong0915/input/core-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_66444181_1
[2.0016000e+03 6.2554112e+08] INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/jjwong0915/input/hadoop-policy.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_66444181_1
[2.0016000e+03 6.2554112e+08] INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/jjwong0915/input/hdfs-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_66444181_1
[2.0016000e+03 6.2554112e+08] INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/jjwong0915/input/httpfs-site.xml._COPYING_ is closed by DFSClient_NONMAPREDUCE_66444181_1
[2.0016000e+03 6.2554112e+08] INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/jjwong0915/input/_SUCCESS is closed by DFSClient_NONMAPREDUCE_1627593271_1
[2.0016000e+03 6.2554112e+08] INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
[2.0016000e+03 6.2554112e+08] INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
[2.0016000e+03 6.2554112e+08] INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
[2.0016000e+03 6.2554112e+08] INFO org.apache.hadoop.util.GSet: VM type       = 64-bit
[2.0238000e+03 6.3381504e+08] INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
[2.0238000e+03 6.3381504e+08] INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
[2.0238000e+03 6.3381504e+08] INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
[2.0238000e+03 6.3381504e+08] INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
[2.0238000e+03 6.3381504e+08] 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:799)
[2.0238000e+03 6.3381504e+08] 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:234)
[2.0238000e+03 6.3381504e+08] 	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:803)
[2.0238000e+03 6.3381504e+08] INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
[2.0238000e+03 6.3381504e+08] 	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:815)
[2.0238000e+03 6.3381504e+08] 	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:779)
[2.0238000e+03 6.3381504e+08] 	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:234)
[2.0238000e+03 6.3381504e+08] 	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.sendHeartbeat(DatanodeProtocolClientSideTranslatorPB.java:154)
[2.0238000e+03 6.3381504e+08] 	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.sendHeartBeat(BPServiceActor.java:497)
[2.0238000e+03 6.3381504e+08] 	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:613)
[2.0238000e+03 6.3381504e+08] INFO org.apache.hadoop.metrics2.impl.MetricsSystemImpl: Scheduled snapshot period at 10 second(s).
[2.0887000e+03 6.5298432e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-29133155-10.142.0.8-1679943450225:blk_1073741826_1002 src: /127.0.0.1:38390 dest: /127.0.0.1:9866
[2.0887000e+03 6.5298432e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-29133155-10.142.0.8-1679943450225:blk_1073741827_1003 src: /127.0.0.1:38396 dest: /127.0.0.1:9866
[2.0887000e+03 6.5298432e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-29133155-10.142.0.8-1679943450225:blk_1073741829_1005 src: /127.0.0.1:38404 dest: /127.0.0.1:9866
[2.0887000e+03 6.5298432e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-29133155-10.142.0.8-1679943450225:blk_1073741832_1008 src: /127.0.0.1:38440 dest: /127.0.0.1:9866
[2.0887000e+03 6.5298432e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-29133155-10.142.0.8-1679943450225:blk_1073741835_1011 src: /127.0.0.1:50574 dest: /127.0.0.1:9866
[2.0887000e+03 6.5298432e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-29133155-10.142.0.8-1679943450225:blk_1073741837_1013 src: /127.0.0.1:50604 dest: /127.0.0.1:9866
[2.0887000e+03 6.5298432e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-29133155-10.142.0.8-1679943450225:blk_1073741839_1015 src: /127.0.0.1:50612 dest: /127.0.0.1:9866
[2.0887000e+03 6.5298432e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-29133155-10.142.0.8-1679943450225:blk_1073741841_1017 src: /127.0.0.1:45722 dest: /127.0.0.1:9866
[2.0887000e+03 6.5298432e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-29133155-10.142.0.8-1679943450225:blk_1073741842_1018 src: /127.0.0.1:45740 dest: /127.0.0.1:9866
[2.1109000e+03 6.6125824e+08] STARTUP_MSG:   host = hadoop-1.us-east1-b.c.workstation-360918.internal/10.142.0.8
[2.1109000e+03 6.6125824e+08] SHUTDOWN_MSG: Shutting down SecondaryNameNode at hadoop-1.us-east1-b.c.workstation-360918.internal/10.142.0.8
[2.1109000e+03 6.6125824e+08] STARTUP_MSG:   host = hadoop-1.us-east1-b.c.workstation-360918.internal/10.142.0.8
[2.1109000e+03 6.6125824e+08] STARTUP_MSG:   host = hadoop-1.us-east1-b.c.workstation-360918.internal/10.142.0.8
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.StateChange: STATE* Leaving safe mode after 0 secs
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.StateChange: STATE* Network topology has 0 racks and 0 datanodes
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:9866
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:9866 for /user/jjwong0915/input/capacity-scheduler.xml._COPYING_
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/jjwong0915/input/capacity-scheduler.xml._COPYING_
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:9866 for /user/jjwong0915/input/core-site.xml._COPYING_
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:9866 for /user/jjwong0915/input/hadoop-policy.xml._COPYING_
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:9866 for /user/jjwong0915/input/hdfs-site.xml._COPYING_
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:9866 for /user/jjwong0915/input/httpfs-site.xml._COPYING_
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:9866 for /user/jjwong0915/input/kms-acls.xml._COPYING_
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:9866 for /user/jjwong0915/input/kms-site.xml._COPYING_
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741832_1008, replicas=127.0.0.1:9866 for /user/jjwong0915/input/yarn-site.xml._COPYING_
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:9866 for /user/jjwong0915/input/_temporary/0/_temporary/attempt_local227564641_0001_m_000000_0/part-m-00000
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741834_1010, replicas=127.0.0.1:9866 for /user/jjwong0915/input/_temporary/0/_temporary/attempt_local227564641_0001_m_000000_0/part-m-00000
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741836_1012, replicas=127.0.0.1:9866 for /user/jjwong0915/input/_temporary/0/_temporary/attempt_local227564641_0001_m_000000_0/part-m-00000
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741837_1013, replicas=127.0.0.1:9866 for /user/jjwong0915/input/_temporary/0/_temporary/attempt_local227564641_0001_m_000000_0/part-m-00000
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741838_1014, replicas=127.0.0.1:9866 for /user/jjwong0915/input/_temporary/0/_temporary/attempt_local227564641_0001_m_000000_0/part-m-00000
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741839_1015, replicas=127.0.0.1:9866 for /user/jjwong0915/input/_temporary/0/_temporary/attempt_local227564641_0001_m_000000_0/part-m-00000
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.StateChange: BLOCK* allocate blk_1073741840_1016, replicas=127.0.0.1:9866 for /user/jjwong0915/input/_temporary/0/_temporary/attempt_local227564641_0001_m_000000_0/part-m-00000
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.StateChange: DIR* completeFile: /user/jjwong0915/input/_temporary/0/_temporary/attempt_local227564641_0001_m_000000_0/part-m-00000 is closed by DFSClient_NONMAPREDUCE_1627593271_1
[2.1109000e+03 6.6125824e+08] SHUTDOWN_MSG: Shutting down NameNode at hadoop-1.us-east1-b.c.workstation-360918.internal/10.142.0.8
[2.1109000e+03 6.6125824e+08] STARTUP_MSG:   host = hadoop-1.us-east1-b.c.workstation-360918.internal/10.142.0.8
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.net.NetworkTopology: Adding a new node: /default-rack/127.0.0.1:9866
[2.1109000e+03 6.6125824e+08] STARTUP_MSG:   host = hadoop-1.us-east1-b.c.workstation-360918.internal/10.142.0.8
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.common.Storage: Block pool storage directory /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225 is not formatted for BP-29133155-10.142.0.8-1679943450225. Formatting ...
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current/replicas doesn't exist 
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-29133155-10.142.0.8-1679943450225 on volume /tmp/hadoop-jjwong0915/dfs/data/current: 0ms
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741825_1001 file /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current/finalized/subdir0/subdir0/blk_1073741825 for deletion
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741826_1002 file /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current/finalized/subdir0/subdir0/blk_1073741826 for deletion
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741827_1003 file /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current/finalized/subdir0/subdir0/blk_1073741827 for deletion
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741828_1004 file /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current/finalized/subdir0/subdir0/blk_1073741828 for deletion
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741829_1005 file /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current/finalized/subdir0/subdir0/blk_1073741829 for deletion
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741830_1006 file /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current/finalized/subdir0/subdir0/blk_1073741830 for deletion
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-29133155-10.142.0.8-1679943450225 blk_1073741825_1001 file /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current/finalized/subdir0/subdir0/blk_1073741825
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741831_1007 file /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current/finalized/subdir0/subdir0/blk_1073741831 for deletion
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-29133155-10.142.0.8-1679943450225 blk_1073741826_1002 file /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current/finalized/subdir0/subdir0/blk_1073741826
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741832_1008 file /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current/finalized/subdir0/subdir0/blk_1073741832 for deletion
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-29133155-10.142.0.8-1679943450225 blk_1073741828_1004 file /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current/finalized/subdir0/subdir0/blk_1073741828
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-29133155-10.142.0.8-1679943450225 blk_1073741829_1005 file /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current/finalized/subdir0/subdir0/blk_1073741829
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-29133155-10.142.0.8-1679943450225 blk_1073741830_1006 file /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current/finalized/subdir0/subdir0/blk_1073741830
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-29133155-10.142.0.8-1679943450225 blk_1073741832_1008 file /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current/finalized/subdir0/subdir0/blk_1073741832
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Scheduling blk_1073741842_1018 file /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current/finalized/subdir0/subdir0/blk_1073741842 for deletion
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-29133155-10.142.0.8-1679943450225 blk_1073741842_1018 file /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current/finalized/subdir0/subdir0/blk_1073741842
[2.1109000e+03 6.6125824e+08] SHUTDOWN_MSG: Shutting down DataNode at hadoop-1.us-east1-b.c.workstation-360918.internal/10.142.0.8
[2.1109000e+03 6.6125824e+08] STARTUP_MSG:   host = hadoop-1.us-east1-b.c.workstation-360918.internal/10.142.0.8
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.BlockPoolSlice: Replica Cache file: /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current/replicas doesn't exist 
[2.1109000e+03 6.6125824e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time to add replicas to map for block pool BP-29133155-10.142.0.8-1679943450225 on volume /tmp/hadoop-jjwong0915/dfs/data/current: 8ms
[2.1869000e+03 6.8456448e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-29133155-10.142.0.8-1679943450225 on /tmp/hadoop-jjwong0915/dfs/data/current: 25ms
[2.1869000e+03 6.8456448e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Time taken to scan block pool BP-29133155-10.142.0.8-1679943450225 on /tmp/hadoop-jjwong0915/dfs/data/current: 28ms
[2.1980000e+03 6.8870144e+08] INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jjwong0915/dfs/namesecondary/in_use.lock acquired by nodename 108513@hadoop-1.us-east1-b.c.workstation-360918.internal
[2.1980000e+03 6.8870144e+08] INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jjwong0915/dfs/namesecondary/in_use.lock acquired by nodename 110732@hadoop-1.us-east1-b.c.workstation-360918.internal
[2.1980000e+03 6.8870144e+08] INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jjwong0915/dfs/name/in_use.lock acquired by nodename 108185@hadoop-1.us-east1-b.c.workstation-360918.internal
[2.1980000e+03 6.8870144e+08] INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jjwong0915/dfs/name/in_use.lock acquired by nodename 110397@hadoop-1.us-east1-b.c.workstation-360918.internal
[2.1980000e+03 6.8870144e+08] INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jjwong0915/dfs/data/in_use.lock acquired by nodename 108330@hadoop-1.us-east1-b.c.workstation-360918.internal
[2.1980000e+03 6.8870144e+08] INFO org.apache.hadoop.hdfs.server.common.Storage: Lock on /tmp/hadoop-jjwong0915/dfs/data/in_use.lock acquired by nodename 110544@hadoop-1.us-east1-b.c.workstation-360918.internal
[2.2202000e+03 6.9697536e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop-jjwong0915/dfs/data/current, StorageType: DISK
[2.2202000e+03 6.9697536e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added volume - /tmp/hadoop-jjwong0915/dfs/data/current, StorageType: DISK
[2.3278e+03 7.2704e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-29133155-10.142.0.8-1679943450225 (Datanode Uuid f58eda39-4a23-440d-8313-5961ae2f38ee) service to localhost/127.0.0.1:9000 beginning handshake with NN
[2.3278e+03 7.2704e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-29133155-10.142.0.8-1679943450225 (Datanode Uuid f58eda39-4a23-440d-8313-5961ae2f38ee) service to localhost/127.0.0.1:9000 successfully registered with NN
[2.3278e+03 7.2704e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-29133155-10.142.0.8-1679943450225 (Datanode Uuid f58eda39-4a23-440d-8313-5961ae2f38ee) service to localhost/127.0.0.1:9000 trying to claim ACTIVE state with txid=1
[2.3278e+03 7.2704e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-29133155-10.142.0.8-1679943450225 (Datanode Uuid f58eda39-4a23-440d-8313-5961ae2f38ee) service to localhost/127.0.0.1:9000
[2.3278e+03 7.2704e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool BP-29133155-10.142.0.8-1679943450225 (Datanode Uuid f58eda39-4a23-440d-8313-5961ae2f38ee) service to localhost/127.0.0.1:9000 beginning handshake with NN
[2.3278e+03 7.2704e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool Block pool BP-29133155-10.142.0.8-1679943450225 (Datanode Uuid f58eda39-4a23-440d-8313-5961ae2f38ee) service to localhost/127.0.0.1:9000 successfully registered with NN
[2.3278e+03 7.2704e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Namenode Block pool BP-29133155-10.142.0.8-1679943450225 (Datanode Uuid f58eda39-4a23-440d-8313-5961ae2f38ee) service to localhost/127.0.0.1:9000 trying to claim ACTIVE state with txid=109
[2.3278e+03 7.2704e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Acknowledging ACTIVE Namenode Block pool BP-29133155-10.142.0.8-1679943450225 (Datanode Uuid f58eda39-4a23-440d-8313-5961ae2f38ee) service to localhost/127.0.0.1:9000
[2.3389000e+03 7.3117696e+08] STARTUP_MSG:   classpath = /home/jjwong0915/hadoop-3.0.0-alpha1/etc/hadoop:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-json-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/paranamer-2.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-util-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-client-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-admin-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/xz-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-config-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/junit-4.11.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/avro-1.7.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/guava-11.0.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-asn1-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-io-2.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-core-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/gson-2.2.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-common-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-util-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/hadoop-auth-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/hadoop-annotations-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/re2j-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-core-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-identity-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-server-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-crypto-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-pkix-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-net-3.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-server-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/activation-1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jettison-1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-simplekdc-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/hadoop-nfs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/hadoop-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/hadoop-common-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/hadoop-hdfs-client-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/netty-all-4.1.0.Beta5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/hpack-0.11.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-discovery-api-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/tephra-api-0.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/antlr-runtime-3.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/antlr-2.7.7.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/tephra-hbase-compat-1.1-0.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/phoenix-core-4.7.0-HBase-1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-zookeeper-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/guice-4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/libthrift-0.9.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-server-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/fastutil-6.5.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-csv-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/joni-2.1.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/stringtemplate-3.2.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-prefix-tree-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-protocol-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-discovery-core-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-el-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/snappy-0.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-client-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/annotations-1.3.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/ST4-4.0.7.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-common-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-common-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-annotations-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/antlr-3.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/metrics-core-3.1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-api-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/guice-assistedinject-3.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/tephra-core-0.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/sqlline-1.1.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/fst-2.24.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/asm-all-5.0.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-procedure-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-core-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-hadoop-compat-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jamon-runtime-2.3.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-api-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-client-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-registry-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0-alpha1.jar
[2.3389000e+03 7.3117696e+08] STARTUP_MSG:   classpath = /home/jjwong0915/hadoop-3.0.0-alpha1/etc/hadoop:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-json-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/paranamer-2.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-util-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-client-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-admin-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/xz-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-config-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/junit-4.11.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/avro-1.7.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/guava-11.0.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-asn1-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-io-2.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-core-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/gson-2.2.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-common-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-util-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/hadoop-auth-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/hadoop-annotations-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/re2j-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-core-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-identity-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-server-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-crypto-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-pkix-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-net-3.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-server-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/activation-1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jettison-1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-simplekdc-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/hadoop-nfs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/hadoop-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/hadoop-common-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/hadoop-hdfs-client-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/netty-all-4.1.0.Beta5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/hpack-0.11.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-discovery-api-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/tephra-api-0.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/antlr-runtime-3.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/antlr-2.7.7.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/tephra-hbase-compat-1.1-0.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/phoenix-core-4.7.0-HBase-1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-zookeeper-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/guice-4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/libthrift-0.9.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-server-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/fastutil-6.5.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-csv-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/joni-2.1.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/stringtemplate-3.2.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-prefix-tree-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-protocol-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-discovery-core-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-el-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/snappy-0.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-client-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/annotations-1.3.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/ST4-4.0.7.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-common-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-common-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-annotations-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/antlr-3.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/metrics-core-3.1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-api-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/guice-assistedinject-3.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/tephra-core-0.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/sqlline-1.1.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/fst-2.24.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/asm-all-5.0.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-procedure-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-core-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-hadoop-compat-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jamon-runtime-2.3.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-api-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-client-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-registry-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0-alpha1.jar
[2.3389000e+03 7.3117696e+08] STARTUP_MSG:   classpath = /home/jjwong0915/hadoop-3.0.0-alpha1/etc/hadoop:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-json-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/paranamer-2.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-util-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-client-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-admin-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/xz-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-config-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/junit-4.11.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/avro-1.7.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/guava-11.0.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-asn1-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-io-2.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-core-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/gson-2.2.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-common-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-util-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/hadoop-auth-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/hadoop-annotations-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/re2j-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-core-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-identity-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-server-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-crypto-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-pkix-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-net-3.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-server-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/activation-1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jettison-1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-simplekdc-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/hadoop-nfs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/hadoop-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/hadoop-common-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/hadoop-hdfs-client-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/netty-all-4.1.0.Beta5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/hpack-0.11.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-discovery-api-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/tephra-api-0.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/antlr-runtime-3.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/antlr-2.7.7.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/tephra-hbase-compat-1.1-0.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/phoenix-core-4.7.0-HBase-1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-zookeeper-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/guice-4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/libthrift-0.9.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-server-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/fastutil-6.5.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-csv-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/joni-2.1.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/stringtemplate-3.2.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-prefix-tree-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-protocol-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-discovery-core-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-el-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/snappy-0.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-client-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/annotations-1.3.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/ST4-4.0.7.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-common-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-common-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-annotations-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/antlr-3.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/metrics-core-3.1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-api-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/guice-assistedinject-3.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/tephra-core-0.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/sqlline-1.1.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/fst-2.24.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/asm-all-5.0.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-procedure-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-core-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-hadoop-compat-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jamon-runtime-2.3.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-api-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-client-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-registry-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0-alpha1.jar
[2.3389000e+03 7.3117696e+08] INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:9866, datanodeUuid=f58eda39-4a23-440d-8313-5961ae2f38ee, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-95b932b1-e70d-4922-a632-09a5454bb088;nsid=1805970196;c=1679943450225) storage f58eda39-4a23-440d-8313-5961ae2f38ee
[2.3389000e+03 7.3117696e+08] STARTUP_MSG:   classpath = /home/jjwong0915/hadoop-3.0.0-alpha1/etc/hadoop:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-json-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/paranamer-2.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-util-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-client-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-admin-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/xz-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-config-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/junit-4.11.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/avro-1.7.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/guava-11.0.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-asn1-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-io-2.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-core-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/gson-2.2.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-common-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-util-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/hadoop-auth-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/hadoop-annotations-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/re2j-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-core-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-identity-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-server-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-crypto-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-pkix-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-net-3.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-server-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/activation-1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jettison-1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-simplekdc-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/hadoop-nfs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/hadoop-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/hadoop-common-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/hadoop-hdfs-client-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/netty-all-4.1.0.Beta5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/hpack-0.11.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-discovery-api-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/tephra-api-0.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/antlr-runtime-3.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/antlr-2.7.7.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/tephra-hbase-compat-1.1-0.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/phoenix-core-4.7.0-HBase-1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-zookeeper-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/guice-4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/libthrift-0.9.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-server-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/fastutil-6.5.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-csv-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/joni-2.1.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/stringtemplate-3.2.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-prefix-tree-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-protocol-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-discovery-core-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-el-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/snappy-0.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-client-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/annotations-1.3.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/ST4-4.0.7.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-common-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-common-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-annotations-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/antlr-3.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/metrics-core-3.1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-api-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/guice-assistedinject-3.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/tephra-core-0.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/sqlline-1.1.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/fst-2.24.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/asm-all-5.0.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-procedure-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-core-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-hadoop-compat-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jamon-runtime-2.3.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-api-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-client-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-registry-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0-alpha1.jar
[2.3389000e+03 7.3117696e+08] INFO org.apache.hadoop.hdfs.StateChange: BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:9866, datanodeUuid=f58eda39-4a23-440d-8313-5961ae2f38ee, infoPort=9864, infoSecurePort=0, ipcPort=9867, storageInfo=lv=-57;cid=CID-95b932b1-e70d-4922-a632-09a5454bb088;nsid=1805970196;c=1679943450225) storage f58eda39-4a23-440d-8313-5961ae2f38ee
[2.3389000e+03 7.3117696e+08] STARTUP_MSG:   classpath = /home/jjwong0915/hadoop-3.0.0-alpha1/etc/hadoop:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-json-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/paranamer-2.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-util-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-client-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-admin-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/xz-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-config-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/junit-4.11.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/avro-1.7.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/guava-11.0.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-asn1-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-io-2.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-core-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/gson-2.2.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-common-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-util-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/hadoop-auth-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/hadoop-annotations-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/re2j-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-core-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-identity-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-server-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-crypto-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-pkix-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-net-3.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-server-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/activation-1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jettison-1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-simplekdc-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/hadoop-nfs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/hadoop-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/hadoop-common-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/hadoop-hdfs-client-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/netty-all-4.1.0.Beta5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/hpack-0.11.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-discovery-api-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/tephra-api-0.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/antlr-runtime-3.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/antlr-2.7.7.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/tephra-hbase-compat-1.1-0.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/phoenix-core-4.7.0-HBase-1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-zookeeper-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/guice-4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/libthrift-0.9.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-server-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/fastutil-6.5.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-csv-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/joni-2.1.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/stringtemplate-3.2.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-prefix-tree-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-protocol-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-discovery-core-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-el-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/snappy-0.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-client-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/annotations-1.3.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/ST4-4.0.7.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-common-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-common-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-annotations-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/antlr-3.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/metrics-core-3.1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-api-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/guice-assistedinject-3.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/tephra-core-0.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/sqlline-1.1.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/fst-2.24.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/asm-all-5.0.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-procedure-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-core-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-hadoop-compat-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jamon-runtime-2.3.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-api-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-client-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-registry-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0-alpha1.jar
[2.3389000e+03 7.3117696e+08] STARTUP_MSG:   classpath = /home/jjwong0915/hadoop-3.0.0-alpha1/etc/hadoop:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jaxb-api-2.2.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-json-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-cli-1.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/paranamer-2.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/java-xmlbuilder-0.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-util-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-client-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jetty-util-6.1.26.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-admin-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/xz-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-config-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/junit-4.11.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/curator-recipes-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/xmlenc-0.52.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/mockito-all-1.8.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/avro-1.7.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/guava-11.0.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-beanutils-1.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jcip-annotations-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/nimbus-jose-jwt-3.9.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-asn1-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/htrace-core4-4.0.1-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-io-2.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/snappy-java-1.0.4.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-core-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/gson-2.2.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/json-smart-1.1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/log4j-1.2.17.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-common-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-util-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/hadoop-auth-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/hadoop-annotations-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/curator-framework-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/re2j-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/httpcore-4.4.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-core-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-configuration-1.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-identity-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-server-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-codec-1.4.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/httpclient-4.5.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-crypto-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jets3t-0.9.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-digester-1.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerby-pkix-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/slf4j-api-1.7.10.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsch-0.1.51.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-beanutils-core-1.8.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jetty-6.1.26.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/zookeeper-3.4.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsr305-3.0.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-lang-2.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-compress-1.4.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/commons-net-3.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/curator-client-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/hamcrest-core-1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-server-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/activation-1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jettison-1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/servlet-api-2.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/kerb-simplekdc-1.0.0-RC2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jsp-api-2.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/slf4j-log4j12-1.7.10.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jetty-sslengine-6.1.26.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/stax-api-1.0-2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/hadoop-nfs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/hadoop-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/common/hadoop-common-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/okio-1.4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/hadoop-hdfs-client-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/netty-all-4.1.0.Beta5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/okhttp-2.4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/xml-apis-1.3.04.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/hpack-0.11.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/lib/xercesImpl-2.9.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-client-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-alpha1-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-discovery-api-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jsp-api-2.1-6.1.14.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/tephra-api-0.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/antlr-runtime-3.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/disruptor-3.3.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/antlr-2.7.7.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/tephra-hbase-compat-1.1-0.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/phoenix-core-4.7.0-HBase-1.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-zookeeper-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/guice-4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/libthrift-0.9.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-server-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/fastutil-6.5.6.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-csv-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/joni-2.1.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-math-2.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/stringtemplate-3.2.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-prefix-tree-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/findbugs-annotations-1.3.9-1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/javassist-3.18.1-GA.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jasper-compiler-5.5.23.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-protocol-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-httpclient-3.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/servlet-api-2.5-6.1.14.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-discovery-core-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/metrics-core-3.0.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/objenesis-2.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/commons-el-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/htrace-core-3.1.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jasper-runtime-5.5.23.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/snappy-0.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-client-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jcodings-1.0.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/annotations-1.3.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/zookeeper-3.4.6-tests.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/ST4-4.0.7.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-common-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-common-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-annotations-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/antlr-3.5.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/metrics-core-3.1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-api-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/javax.inject-1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/guice-assistedinject-3.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-hadoop2-compat-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/tephra-core-0.7.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/metrics-core-2.2.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/sqlline-1.1.8.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/fst-2.24.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/asm-all-5.0.2.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/curator-test-2.7.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-procedure-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/twill-core-0.6.0-incubating.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jsp-2.1-6.1.14.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/hbase-hadoop-compat-1.1.3.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/lib/jamon-runtime-2.3.1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-common-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-api-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-client-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-timelineservice-hbase-tests-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-registry-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-timelineservice-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-tests-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.0.0-alpha1.jar:/home/jjwong0915/hadoop-3.0.0-alpha1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.0.0-alpha1.jar
[2.3500000e+03 7.3531392e+08] java.io.IOException: Failed on local exception: java.io.InterruptedIOException: Interrupted while waiting for IO on channel java.nio.channels.SocketChannel[connected local=/127.0.0.1:53986 remote=localhost/127.0.0.1:9000]. 60000 millis timeout left.; Host Details : local host is: "hadoop-1.us-east1-b.c.workstation-360918.internal/10.142.0.8"; destination host is: "localhost":9000; 
[2.3611000e+03 7.3945088e+08] INFO org.apache.hadoop.util.GSet: 2.0% max memory 873 MB = 17.5 MB
[2.3611000e+03 7.3945088e+08] INFO org.apache.hadoop.util.GSet: 1.0% max memory 873 MB = 8.7 MB
[2.3611000e+03 7.3945088e+08] INFO org.apache.hadoop.util.GSet: 0.25% max memory 873 MB = 2.2 MB
[2.3611000e+03 7.3945088e+08] INFO org.apache.hadoop.util.GSet: 2.0% max memory 873 MB = 17.5 MB
[2.3611000e+03 7.3945088e+08] INFO org.apache.hadoop.util.GSet: 1.0% max memory 873 MB = 8.7 MB
[2.3611000e+03 7.3945088e+08] INFO org.apache.hadoop.util.GSet: 0.25% max memory 873 MB = 2.2 MB
[2.3611000e+03 7.3945088e+08] INFO org.apache.hadoop.util.GSet: 2.0% max memory 873 MB = 17.5 MB
[2.3611000e+03 7.3945088e+08] INFO org.apache.hadoop.util.GSet: 1.0% max memory 873 MB = 8.7 MB
[2.3611000e+03 7.3945088e+08] INFO org.apache.hadoop.util.GSet: 0.25% max memory 873 MB = 2.2 MB
[2.3611000e+03 7.3945088e+08] INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 873 MB = 268.2 KB
[2.3611000e+03 7.3945088e+08] INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
[2.3611000e+03 7.3945088e+08] INFO org.apache.hadoop.util.GSet: 2.0% max memory 873 MB = 17.5 MB
[2.3611000e+03 7.3945088e+08] INFO org.apache.hadoop.util.GSet: 1.0% max memory 873 MB = 8.7 MB
[2.3611000e+03 7.3945088e+08] INFO org.apache.hadoop.util.GSet: 0.25% max memory 873 MB = 2.2 MB
[2.3611000e+03 7.3945088e+08] INFO org.apache.hadoop.util.GSet: 0.029999999329447746% max memory 873 MB = 268.2 KB
[2.3611000e+03 7.3945088e+08] INFO org.apache.hadoop.hdfs.StateChange: STATE* UnderReplicatedBlocks has 0 blocks
[2.557500e+03 8.026112e+08] INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225
[2.557500e+03 8.026112e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-29133155-10.142.0.8-1679943450225 on volume /tmp/hadoop-jjwong0915/dfs/data/current...
[2.557500e+03 8.026112e+08] INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop-jjwong0915/dfs/data, DS-39f00f43-9d22-446b-8189-e4fc6a57c36f): finished scanning block pool BP-29133155-10.142.0.8-1679943450225
[2.557500e+03 8.026112e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-29133155-10.142.0.8-1679943450225 blk_1073741827_1003 file /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current/finalized/subdir0/subdir0/blk_1073741827
[2.557500e+03 8.026112e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetAsyncDiskService: Deleted BP-29133155-10.142.0.8-1679943450225 blk_1073741831_1007 file /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current/finalized/subdir0/subdir0/blk_1073741831
[2.557500e+03 8.026112e+08] INFO org.apache.hadoop.hdfs.server.common.Storage: Locking is disabled for /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225
[2.557500e+03 8.026112e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Scanning block pool BP-29133155-10.142.0.8-1679943450225 on volume /tmp/hadoop-jjwong0915/dfs/data/current...
[2.589100e+03 8.093696e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:38374, dest: /127.0.0.1:9866, bytes: 4436, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_66444181_1, offset: 0, srvID: f58eda39-4a23-440d-8313-5961ae2f38ee, blockid: BP-29133155-10.142.0.8-1679943450225:blk_1073741825_1001, duration: 13858608
[2.589100e+03 8.093696e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace: src: /127.0.0.1:50620, dest: /127.0.0.1:9866, bytes: 134217728, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1627593271_1, offset: 0, srvID: f58eda39-4a23-440d-8313-5961ae2f38ee, blockid: BP-29133155-10.142.0.8-1679943450225:blk_1073741840_1016, duration: 1250796078
[2.6113000e+03 8.1764352e+08] INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:9868
[2.6113000e+03 8.1764352e+08] INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for secondary at: http://0.0.0.0:9868
[2.6113000e+03 8.1764352e+08] INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870
[2.6113000e+03 8.1764352e+08] INFO org.apache.hadoop.hdfs.DFSUtil: Starting Web-server for hdfs at: http://0.0.0.0:9870
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2023 Mar 27 18:57:44
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2023 Mar 27 19:09:45
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
[2.7966000e+03 8.7666688e+08] WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
[2.7966000e+03 8.7666688e+08] WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2023 Mar 27 18:57:38
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 192 msecs
[2.7966000e+03 8.7666688e+08] WARN org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: forceExit used when normal exist would suffice. Treating force exit as normal safe mode exit.
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Number of transactions: 54 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 28 Number of syncs: 26 SyncTimes(ms): 349 
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
[2.7966000e+03 8.7666688e+08] WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one image storage directory (dfs.namenode.name.dir) configured. Beware of data loss due to lack of redundant storage directories!
[2.7966000e+03 8.7666688e+08] WARN org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Only one namespace edits storage directory (dfs.namenode.edits.dir) configured. Beware of data loss due to lack of redundant storage directories!
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.block.invalidate.limit=1000
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: The block deletion will start around 2023 Mar 27 19:09:39
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: dfs.block.access.token.enable=false
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Caching file names occuring more than 10 times
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.namenode.top.metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache on namenode is enabled
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Finished loading FSImage in 499 msecs
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Initializing quota with 4 thread(s)
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Balancing bandwidth is 10485760 bytes/s
[2.7966000e+03 8.7666688e+08] INFO org.apache.hadoop.security.authentication.server.AuthenticationFilter: Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
[2.8077000e+03 8.8080384e+08] INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
[2.8077000e+03 8.8080384e+08] INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint Period   :3600 secs (60 min)
[2.8393000e+03 8.8756224e+08] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.01s. The fsimage download took 0.01s at 0.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-jjwong0915/dfs/namesecondary/current/fsimage.ckpt_0000000000000000000 took 0.00s.
[2.8393000e+03 8.8756224e+08] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 5000.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-jjwong0915/dfs/namesecondary/current/edits_tmp_0000000000000000001-0000000000000000054_0000000000090835158 took 0.00s.
[2.8393000e+03 8.8756224e+08] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.01s. The fsimage download took 0.01s at 0.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-jjwong0915/dfs/namesecondary/current/fsimage.ckpt_0000000000000000054 took 0.00s.
[2.8393000e+03 8.8756224e+08] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.01s. The fsimage download took 0.00s at 256000.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-jjwong0915/dfs/namesecondary/current/edits_tmp_0000000000000000055-0000000000000000108_0000000000091556086 took 0.00s.
[2.8393000e+03 8.8756224e+08] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-jjwong0915/dfs/namesecondary/current/edits_tmp_0000000000000000109-0000000000000000110_0000000000091556103 took 0.00s.
[2.8393000e+03 8.8756224e+08] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-jjwong0915/dfs/name/current/fsimage.ckpt_0000000000000000054 took 0.00s.
[2.8393000e+03 8.8756224e+08] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Combined time for fsimage download and fsync to all disks took 0.00s. The fsimage download took 0.00s at 0.00 KB/s. Synchronous (fsync) write to disk of /tmp/hadoop-jjwong0915/dfs/name/current/fsimage.ckpt_0000000000000000110 took 0.00s.
[2.8726000e+03 8.9997312e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 5 milliseconds
[2.9281000e+03 9.2065792e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jjwong0915/dfs/namesecondary/current/fsimage.ckpt_0000000000000000054 of size 483 bytes saved in 0 seconds.
[2.9281000e+03 9.2065792e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Image file /tmp/hadoop-jjwong0915/dfs/namesecondary/current/fsimage.ckpt_0000000000000000110 of size 816 bytes saved in 0 seconds.
[2.9486000e+03 9.2327936e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: Quota initialization completed in 3 milliseconds
[2.9392000e+03 9.2479488e+08] INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 54
[2.9392000e+03 9.2479488e+08] INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 54
[3.024600e+03 9.465856e+08] INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
[3.024600e+03 9.465856e+08] INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Image has changed. Downloading updated image from NN.
[3.0357000e+03 9.5072256e+08] INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
[3.0357000e+03 9.5072256e+08] INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
[3.0357000e+03 9.5072256e+08] INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
[3.0357000e+03 9.5072256e+08] INFO org.apache.hadoop.hdfs.server.namenode.NameNode: fs.defaultFS is hdfs://localhost:9000
[3.0357000e+03 9.5072256e+08] INFO org.apache.hadoop.hdfs.server.namenode.NameNode: Clients are to use localhost:9000 to access this namenode/service.
[3.0357000e+03 9.5072256e+08] INFO org.apache.hadoop.hdfs.server.namenode.NameNode: RPC server is binding to localhost:9000
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jjwong0915 (auth:SIMPLE)
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
[3.0468000e+03 9.5485952e+08] ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: RECEIVED SIGNAL 15: SIGTERM
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: SHUTDOWN_MSG: 
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: STARTUP_MSG: 
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jjwong0915 (auth:SIMPLE)
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Web server init done
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 2 stream(s).
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jjwong0915 (auth:SIMPLE)
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSImage: No edit log streams selected.
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
[3.0468000e+03 9.5485952e+08] ERROR org.apache.hadoop.hdfs.server.namenode.NameNode: RECEIVED SIGNAL 15: SIGTERM
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.NameNode: SHUTDOWN_MSG: 
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.NameNode: STARTUP_MSG: 
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.NameNode: createNameNode []
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Edit logging is async:false
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: KeyProvider: null
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsLock is fair:true
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: fsOwner             = jjwong0915 (auth:SIMPLE)
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: supergroup          = supergroup
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: isPermissionEnabled = true
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: HA Enabled: false
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplication             = 512
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: replicationRecheckInterval = 3000
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: encryptDataTransfer        = false
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxNumBlocksToLog          = 1000
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: ACLs enabled? false
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSDirectory: XAttrs enabled? true
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Registered FSNamesystemState MBean
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: initializing replication queues
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 9
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Rolling edit logs
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = jjwong0915
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Generated and persisted new Datanode UUID f58eda39-4a23-440d-8313-5961ae2f38ee
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-39f00f43-9d22-446b-8189-e4fc6a57c36f
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 4ms
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1679952165821ms with interval of 21600000ms
[3.0468000e+03 9.5485952e+08] ERROR org.apache.hadoop.hdfs.server.datanode.DataNode: RECEIVED SIGNAL 15: SIGTERM
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: SHUTDOWN_MSG: 
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: STARTUP_MSG: 
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Number threads for balancing is 50
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: dnUserName = jjwong0915
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: supergroup = supergroup
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Refresh request received for nameservices: null
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting BPOfferServices for nameservices: <default>
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Added new volume: DS-39f00f43-9d22-446b-8189-e4fc6a57c36f
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Registered FSDatasetState MBean
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Volume reference is released.
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to add all replicas to map: 9ms
[3.0468000e+03 9.5485952e+08] INFO org.apache.hadoop.hdfs.server.datanode.DirectoryScanner: Periodic Directory Tree Verification scan starting at 1679949237177ms with interval of 21600000ms
[3.0579000e+03 9.5899648e+08] INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
[3.0579000e+03 9.5899648e+08] INFO org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Log Size Trigger    :1000000 txns
[3.0579000e+03 9.5899648e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 109
[3.0690000e+03 9.6313344e+08] WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 483
[3.0690000e+03 9.6313344e+08] WARN org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Checkpoint done. New Image Size: 816
[3.1228000e+03 9.7816576e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
[3.1228000e+03 9.7816576e+08] INFO org.apache.hadoop.hdfs.server.namenode.EditLogFileOutputStream: Nothing to flush
[3.1228000e+03 9.7816576e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.CacheReplicationMonitor: Starting CacheReplicationMonitor with interval 30000 milliseconds
[3.1228000e+03 9.7816576e+08] INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
[3.1228000e+03 9.7816576e+08] WARN org.apache.hadoop.hdfs.server.datanode.DataNode: IOException in offerService
[3.1228000e+03 9.7816576e+08] INFO org.apache.hadoop.hdfs.server.datanode.BlockScanner: Initialized block scanner with targetBytesPerSec 1048576
[3.1339000e+03 9.8230272e+08] INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6bca7e0d expecting start txid #55
[3.1450000e+03 9.8643968e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
[3.1450000e+03 9.8643968e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
[3.1450000e+03 9.8643968e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
[3.1450000e+03 9.8643968e+08] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: maxReplicationStreams      = 2
[3.1766000e+03 9.9319808e+08] INFO org.apache.hadoop.hdfs.server.namenode.Checkpointer: Checkpointer about to load edits from 1 stream(s).
[3.198800e+03 1.001472e+09] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
[3.198800e+03 1.001472e+09] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Image Transfer timeout configured to 60000 milliseconds
[3.198800e+03 1.001472e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 3 INodes.
[3.198800e+03 1.001472e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 3 INodes.
[3.24320000e+03 1.01801984e+09] INFO org.apache.hadoop.hdfs.server.common.Storage: Generated new storageID DS-39f00f43-9d22-446b-8189-e4fc6a57c36f for directory /tmp/hadoop-jjwong0915/dfs/data
[3.24320000e+03 1.01801984e+09] INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop-jjwong0915/dfs/data, DS-39f00f43-9d22-446b-8189-e4fc6a57c36f): no suitable block pools found to scan.  Waiting 1814399864 ms.
[3.24320000e+03 1.01801984e+09] INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: VolumeScanner(/tmp/hadoop-jjwong0915/dfs/data, DS-39f00f43-9d22-446b-8189-e4fc6a57c36f): no suitable block pools found to scan.  Waiting 1813678645 ms.
[3.27480000e+03 1.02477824e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
[3.27480000e+03 1.02477824e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
[3.27480000e+03 1.02477824e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
[3.27480000e+03 1.02477824e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
[3.27480000e+03 1.02477824e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
[3.27480000e+03 1.02477824e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
[3.27480000e+03 1.02477824e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 1
[3.27480000e+03 1.02477824e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Ending log segment 1
[3.27480000e+03 1.02477824e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: defaultReplication         = 1
[3.27480000e+03 1.02477824e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: minReplication             = 1
[3.27480000e+03 1.02477824e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoop-1.us-east1-b.c.workstation-360918.internal
[3.27480000e+03 1.02477824e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Configured hostname is hadoop-1.us-east1-b.c.workstation-360918.internal
[3.26540000e+03 1.02629376e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jjwong0915/dfs/namesecondary/current/fsimage.ckpt_0000000000000000054 using no compression
[3.26540000e+03 1.02629376e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Saving image file /tmp/hadoop-jjwong0915/dfs/namesecondary/current/fsimage.ckpt_0000000000000000110 using no compression
[3.29700000e+03 1.03305216e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 55
[3.29700000e+03 1.03305216e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 111
[3.29700000e+03 1.03305216e+09] 	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:807)
[3.28760000e+03 1.03456768e+09] INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jjwong0915/dfs/namesecondary/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
[3.28760000e+03 1.03456768e+09] INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Purging old image FSImageFile(file=/tmp/hadoop-jjwong0915/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
[3.30810000e+03 1.03718912e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSEditLog: Starting log segment at 109
[3.31920000e+03 1.04132608e+09] INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-jjwong0915/dfs/name/current
[3.31920000e+03 1.04132608e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-jjwong0915/dfs/name/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
[3.31920000e+03 1.04132608e+09] INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /tmp/hadoop-jjwong0915/dfs/name/current
[3.31920000e+03 1.04132608e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Planning to load image: FSImageFile(file=/tmp/hadoop-jjwong0915/dfs/name/current/fsimage_0000000000000000054, cpktTxId=0000000000000000054)
[3.31920000e+03 1.04132608e+09] INFO org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream: Fast-forwarding stream '/tmp/hadoop-jjwong0915/dfs/name/current/edits_0000000000000000055-0000000000000000108' to transaction ID 55
[3.33970000e+03 1.04394752e+09] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:9870/imagetransfer?getedit=1&startTxId=1&endTxId=54&storageInfo=-64:1805970196:1679943450225:CID-95b932b1-e70d-4922-a632-09a5454bb088
[3.35080000e+03 1.04808448e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
[3.35080000e+03 1.04808448e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatPBINode: Loading 1 INodes.
[3.3414e+03 1.0496e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jjwong0915/dfs/namesecondary/current/edits_0000000000000000109-0000000000000000110 expecting start txid #109
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN f58eda39-4a23-440d-8313-5961ae2f38ee (127.0.0.1:9866).
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-39f00f43-9d22-446b-8189-e4fc6a57c36f for DN 127.0.0.1:9866
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockReportLeaseManager: Registered DN f58eda39-4a23-440d-8313-5961ae2f38ee (127.0.0.1:9866).
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.DatanodeDescriptor: Adding new storage ID DS-39f00f43-9d22-446b-8189-e4fc6a57c36f for DN 127.0.0.1:9866
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of invalid blocks          = 0
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of under-replicated blocks = 0
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of  over-replicated blocks = 0
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Number of blocks being written    = 0
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-29133155-10.142.0.8-1679943450225
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.common.Storage: Formatting block pool BP-29133155-10.142.0.8-1679943450225 directory /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-29133155-10.142.0.8-1679943450225
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-29133155-10.142.0.8-1679943450225: 28ms
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-29133155-10.142.0.8-1679943450225
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-29133155-10.142.0.8-1679943450225:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-29133155-10.142.0.8-1679943450225:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-29133155-10.142.0.8-1679943450225:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-29133155-10.142.0.8-1679943450225:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-29133155-10.142.0.8-1679943450225:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-29133155-10.142.0.8-1679943450225:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-29133155-10.142.0.8-1679943450225:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-29133155-10.142.0.8-1679943450225:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-29133155-10.142.0.8-1679943450225:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-29133155-10.142.0.8-1679943450225:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-29133155-10.142.0.8-1679943450225:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-29133155-10.142.0.8-1679943450225:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-29133155-10.142.0.8-1679943450225:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-29133155-10.142.0.8-1679943450225:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-29133155-10.142.0.8-1679943450225:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-29133155-10.142.0.8-1679943450225:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-29133155-10.142.0.8-1679943450225:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: PacketResponder: BP-29133155-10.142.0.8-1679943450225:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.web.DatanodeHttpServer: Listening HTTP traffic on /0.0.0.0:9864
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.common.Storage: Analyzing storage directories for bpid BP-29133155-10.142.0.8-1679943450225
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding block pool BP-29133155-10.142.0.8-1679943450225
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Total time to scan all replicas for block pool BP-29133155-10.142.0.8-1679943450225: 31ms
[3.38410000e+03 1.06049536e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Got finalize command for block pool BP-29133155-10.142.0.8-1679943450225
[3.39520000e+03 1.06463232e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 54 from /tmp/hadoop-jjwong0915/dfs/namesecondary/current/fsimage_0000000000000000054
[3.39520000e+03 1.06463232e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 54 from /tmp/hadoop-jjwong0915/dfs/name/current/fsimage_0000000000000000054
[3.41740000e+03 1.07290624e+09] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000000 size 338 bytes.
[3.41740000e+03 1.07290624e+09] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000054 size 483 bytes.
[3.41740000e+03 1.07290624e+09] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000054 size 483 bytes.
[3.41740000e+03 1.07290624e+09] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file fsimage.ckpt_0000000000000000110 size 816 bytes.
[3.4285000e+03 1.0770432e+09] INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-jjwong0915/dfs/name/current/edits_inprogress_0000000000000000001 -> /tmp/hadoop-jjwong0915/dfs/name/current/edits_0000000000000000001-0000000000000000054
[3.4285000e+03 1.0770432e+09] INFO org.apache.hadoop.hdfs.server.namenode.NNStorageRetentionManager: Going to retain 2 images with txid >= 0
[3.4285000e+03 1.0770432e+09] INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-jjwong0915/dfs/name/current/edits_inprogress_0000000000000000055 -> /tmp/hadoop-jjwong0915/dfs/name/current/edits_0000000000000000055-0000000000000000108
[3.4285000e+03 1.0770432e+09] INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /tmp/hadoop-jjwong0915/dfs/name/current/edits_inprogress_0000000000000000109 -> /tmp/hadoop-jjwong0915/dfs/name/current/edits_0000000000000000109-0000000000000000110
[3.4601000e+03 1.0838016e+09] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-29133155-10.142.0.8-1679943450225 on volume /tmp/hadoop-jjwong0915/dfs/data/current...
[3.4601000e+03 1.0838016e+09] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Adding replicas to map for block pool BP-29133155-10.142.0.8-1679943450225 on volume /tmp/hadoop-jjwong0915/dfs/data/current...
[3.49170e+03 1.09056e+09] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:9870/imagetransfer?getimage=1&txid=54&storageInfo=-64:1805970196:1679943450225:CID-95b932b1-e70d-4922-a632-09a5454bb088&bootstrapstandby=false
[3.49170e+03 1.09056e+09] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:9870/imagetransfer?getedit=1&startTxId=55&endTxId=108&storageInfo=-64:1805970196:1679943450225:CID-95b932b1-e70d-4922-a632-09a5454bb088
[3.49170e+03 1.09056e+09] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:9870/imagetransfer?getedit=1&startTxId=109&endTxId=110&storageInfo=-64:1805970196:1679943450225:CID-95b932b1-e70d-4922-a632-09a5454bb088
[3.49340000e+03 1.09621248e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-jjwong0915/dfs/namesecondary
[3.49340000e+03 1.09621248e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImageTransactionalStorageInspector: No version file in /tmp/hadoop-jjwong0915/dfs/namesecondary
[3.5156000e+03 1.1044864e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jjwong0915/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000054
[3.5156000e+03 1.1044864e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jjwong0915/dfs/namesecondary/current/edits_0000000000000000055-0000000000000000108 expecting start txid #55
[3.5156000e+03 1.1044864e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jjwong0915/dfs/namesecondary/current/edits_0000000000000000055-0000000000000000108
[3.5156000e+03 1.1044864e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jjwong0915/dfs/namesecondary/current/edits_0000000000000000109-0000000000000000110
[3.5156000e+03 1.1044864e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Start loading edits file /tmp/hadoop-jjwong0915/dfs/name/current/edits_0000000000000000055-0000000000000000108
[3.53610000e+03 1.10710784e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
[3.53610000e+03 1.10710784e+09] INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
[3.53610000e+03 1.10710784e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
[3.53610000e+03 1.10710784e+09] INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
[3.53610000e+03 1.10710784e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
[3.53610000e+03 1.10710784e+09] INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
[3.53610000e+03 1.10710784e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImageFormatProtobuf: Loaded FSImage in 0 seconds.
[3.53610000e+03 1.10710784e+09] INFO org.apache.hadoop.hdfs.server.namenode.NameCache: initialized with 0 entries 0 lookups
[3.55830000e+03 1.11538176e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading /tmp/hadoop-jjwong0915/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000054 expecting start txid #1
[3.61210000e+03 1.13041408e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
[3.61210000e+03 1.13041408e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Roll Edit Log from 127.0.0.1
[3.61210000e+03 1.13041408e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-29133155-10.142.0.8-1679943450225:blk_1073741825_1001 src: /127.0.0.1:38374 dest: /127.0.0.1:9866
[3.61210000e+03 1.13041408e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-29133155-10.142.0.8-1679943450225:blk_1073741828_1004 src: /127.0.0.1:38398 dest: /127.0.0.1:9866
[3.61210000e+03 1.13041408e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-29133155-10.142.0.8-1679943450225:blk_1073741830_1006 src: /127.0.0.1:38420 dest: /127.0.0.1:9866
[3.61210000e+03 1.13041408e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-29133155-10.142.0.8-1679943450225:blk_1073741831_1007 src: /127.0.0.1:38434 dest: /127.0.0.1:9866
[3.61210000e+03 1.13041408e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-29133155-10.142.0.8-1679943450225:blk_1073741833_1009 src: /127.0.0.1:49746 dest: /127.0.0.1:9866
[3.61210000e+03 1.13041408e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-29133155-10.142.0.8-1679943450225:blk_1073741834_1010 src: /127.0.0.1:50562 dest: /127.0.0.1:9866
[3.61210000e+03 1.13041408e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-29133155-10.142.0.8-1679943450225:blk_1073741836_1012 src: /127.0.0.1:50588 dest: /127.0.0.1:9866
[3.61210000e+03 1.13041408e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-29133155-10.142.0.8-1679943450225:blk_1073741838_1014 src: /127.0.0.1:50610 dest: /127.0.0.1:9866
[3.61210000e+03 1.13041408e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Receiving BP-29133155-10.142.0.8-1679943450225:blk_1073741840_1016 src: /127.0.0.1:50620 dest: /127.0.0.1:9866
[3.62320000e+03 1.13455104e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
[3.62320000e+03 1.13455104e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
[3.62320000e+03 1.13455104e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:9000 starting to offer service
[3.62320000e+03 1.13455104e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: For namenode localhost/127.0.0.1:9000 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
[3.634300e+03 1.138688e+09] INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
[3.634300e+03 1.138688e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: Total number of blocks            = 0
[3.634300e+03 1.138688e+09] INFO org.apache.hadoop.hdfs.server.blockmanagement.BlockManager: StorageInfo TreeSet fill ratio DS-39f00f43-9d22-446b-8189-e4fc6a57c36f : 1.0
[3.634300e+03 1.138688e+09] INFO org.apache.hadoop.hdfs.server.namenode.LeaseManager: Number of blocks under construction: 0
[3.634300e+03 1.138688e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
[3.634300e+03 1.138688e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened IPC server at /0.0.0.0:9867
[3.64540000e+03 1.14282496e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jjwong0915/dfs/name/current/edits_0000000000000000055-0000000000000000108 of size 1048576 edits # 54 loaded in 0 seconds
[3.69920000e+03 1.15785728e+09] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Opening connection to http://localhost:9870/imagetransfer?getimage=1&txid=0&storageInfo=-64:1805970196:1679943450225:CID-95b932b1-e70d-4922-a632-09a5454bb088&bootstrapstandby=false
[3.6898000e+03 1.1593728e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jjwong0915/dfs/namesecondary/current/edits_0000000000000000001-0000000000000000054 of size 5397 edits # 54 loaded in 0 seconds
[3.6898000e+03 1.1593728e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jjwong0915/dfs/namesecondary/current/edits_0000000000000000055-0000000000000000108 of size 1048576 edits # 54 loaded in 0 seconds
[3.6898000e+03 1.1593728e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file /tmp/hadoop-jjwong0915/dfs/namesecondary/current/edits_0000000000000000109-0000000000000000110 of size 42 edits # 2 loaded in 0 seconds
[3.71030000e+03 1.16199424e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
[3.71030000e+03 1.16199424e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Starting DataNode with maxLockedMemory = 0
[3.83070000e+03 1.20184832e+09] INFO org.apache.hadoop.hdfs.server.datanode.VolumeScanner: Now scanning bpid BP-29133155-10.142.0.8-1679943450225 on volume /tmp/hadoop-jjwong0915/dfs/data
[3.83070000e+03 1.20184832e+09] INFO org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl: Cached dfsUsed found for /tmp/hadoop-jjwong0915/dfs/data/current/BP-29133155-10.142.0.8-1679943450225/current: 1110944007
[3.87340000e+03 1.21274368e+09] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 54 to namenode at http://localhost:9870 in 0.03 seconds
[3.87340000e+03 1.21274368e+09] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Uploaded image with txid 110 to namenode at http://localhost:9870 in 0.03 seconds
[3.87340000e+03 1.21274368e+09] INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
[3.87340000e+03 1.21274368e+09] INFO org.apache.hadoop.hdfs.server.namenode.NameNode: NameNode RPC up at: localhost/127.0.0.1:9000
[3.88450000e+03 1.21688064e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
[3.88450000e+03 1.21688064e+09] INFO org.apache.hadoop.hdfs.server.datanode.DataNode: Opened streaming server at /0.0.0.0:9866
[3.90670000e+03 1.22515456e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-jjwong0915/dfs/namesecondary/current/fsimage_0000000000000000000
[3.90670000e+03 1.22515456e+09] INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Loaded image for txid 0 from /tmp/hadoop-jjwong0915/dfs/name/current/fsimage_0000000000000000000
[4.08090000e+03 1.28004096e+09] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000001-0000000000000000054_0000000000090835158 size 0 bytes.
[4.08090000e+03 1.28004096e+09] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000055-0000000000000000108_0000000000091556086 size 0 bytes.
[4.08090000e+03 1.28004096e+09] INFO org.apache.hadoop.hdfs.server.namenode.TransferFsImage: Downloaded file edits_tmp_0000000000000000109-0000000000000000110_0000000000091556103 size 0 bytes.
